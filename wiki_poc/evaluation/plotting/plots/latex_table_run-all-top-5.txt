\begin{tabular}{lrrr}
\toprule
model_class & size [billions] & accuracy & partial name matching score \\
\midrule
gpt_4 & 175.00 & 0.71 & 0.16 \\
mt0 & 13.00 & 0.38 & 0.42 \\
flan_t5 & 11.00 & 0.38 & 0.44 \\
incite_instruct & 3.00 & 0.37 & 0.51 \\
flan_t5 & 3.00 & 0.36 & 0.47 \\
bloomz & 7.10 & 0.35 & 0.45 \\
flan_t5 & 0.78 & 0.34 & 0.49 \\
bloomz & 1.10 & 0.32 & 0.47 \\
mt0 & 1.20 & 0.32 & 0.46 \\
bloomz & 1.70 & 0.32 & 0.47 \\
flan_t5 & 0.25 & 0.30 & 0.50 \\
bloomz & 3.00 & 0.30 & 0.47 \\
flan_t5 & 0.08 & 0.28 & 0.50 \\
t5 & 3.00 & 0.27 & 0.57 \\
llama & 7.00 & 0.26 & 0.52 \\
mt0 & 0.58 & 0.26 & 0.48 \\
t5 & 0.77 & 0.24 & 0.54 \\
bloom & 7.10 & 0.21 & 0.56 \\
roberta & 0.35 & 0.21 & 0.84 \\
mpt & 7.00 & 0.20 & 0.50 \\
mpt_instruct & 6.70 & 0.20 & 0.56 \\
bloom & 3.00 & 0.19 & 0.56 \\
roberta & 0.12 & 0.19 & 0.84 \\
distilbert_squad & 0.06 & 0.17 & 0.59 \\
incite & 3.00 & 0.17 & 0.54 \\
bloom & 1.70 & 0.15 & 0.52 \\
t5 & 0.06 & 0.13 & 0.67 \\
bloom & 1.10 & 0.09 & 0.59 \\
roberta_squad & 0.12 & 0.08 & 0.82 \\
cerebras & 13.00 & 0.06 & 0.77 \\
falcon_instruct & 7.00 & 0.05 & 0.65 \\
t5 & 0.22 & 0.04 & 0.60 \\
pythia & 12.00 & 0.04 & 0.70 \\
cerebras & 6.70 & 0.04 & 0.70 \\
pythia & 0.41 & 0.03 & 0.71 \\
gptj & 6.00 & 0.03 & 0.70 \\
cerebras & 1.30 & 0.03 & 0.67 \\
pythia & 2.80 & 0.03 & 0.74 \\
gpt_neox & 20.00 & 0.03 & 0.69 \\
falcon & 7.00 & 0.03 & 0.66 \\
pythia & 1.40 & 0.03 & 0.71 \\
cerebras & 2.70 & 0.03 & 0.73 \\
pythia & 0.07 & 0.03 & 0.70 \\
roberta_squad & 0.35 & 0.02 & 0.83 \\
pythia & 0.16 & 0.02 & 0.67 \\
pythia & 6.90 & 0.02 & 0.82 \\
cerebras & 0.11 & 0.02 & 0.75 \\
distilbert & 0.07 & 0.01 & 0.72 \\
\bottomrule
\end{tabular}
