{
    "key": "sentences-count-ablation",
    "flan_t5-11b": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.3468067048589009,
            "precision": 0.4570871250449799,
            "last_name_accuracy": 0.244005941014216,
            "last_name_precision": 1.0026086956521738,
            "weighted_score": 0.2799862083598557
        },
        "original": {
            "accuracy": 0.41098370549185276,
            "precision": 0.4508307962481789,
            "last_name_accuracy": 0.3031583182458258,
            "last_name_precision": 1.002322495023225,
            "weighted_score": 0.3408972037819352
        }
    },
    "t0-11b": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.3238913643114789,
            "precision": 0.4458802454796905,
            "last_name_accuracy": 0.22459155527265012,
            "last_name_precision": 1.0061407652338215,
            "weighted_score": 0.2593464884362402
        },
        "original": {
            "accuracy": 0.3820156910078455,
            "precision": 0.43331839787640575,
            "last_name_accuracy": 0.2779118889559445,
            "last_name_precision": 1.0047050307636627,
            "weighted_score": 0.31434821967410986
        }
    },
    "bloomz-7b1": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.15605771270952684,
            "precision": 0.563264460112523,
            "last_name_accuracy": 0.0787184383619775,
            "last_name_precision": 1.005390835579515,
            "weighted_score": 0.10578718438361978
        },
        "original": {
            "accuracy": 0.1772279219472943,
            "precision": 0.5538685492266098,
            "last_name_accuracy": 0.09334138000402334,
            "last_name_precision": 1.0258620689655173,
            "weighted_score": 0.12270166968416818
        }
    },
    "mt0-13b": {
        "size": 13.0,
        "paraphrased": {
            "accuracy": 0.35285380861447063,
            "precision": 0.42640902779864326,
            "last_name_accuracy": 0.25206874602164225,
            "last_name_precision": 1.0025252525252526,
            "weighted_score": 0.2873435179291322
        },
        "original": {
            "accuracy": 0.4451820559243613,
            "precision": 0.3984170262898428,
            "last_name_accuracy": 0.32870649768658217,
            "last_name_precision": 1.0033659730722153,
            "weighted_score": 0.3694729430698048
        }
    },
    "incite_instruct-3b": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.2379588372586463,
            "precision": 0.643049897811507,
            "last_name_accuracy": 0.12614046255039252,
            "last_name_precision": 1.0529857022708158,
            "weighted_score": 0.16527689369828136
        },
        "original": {
            "accuracy": 0.21454435727217863,
            "precision": 1.0331746835426476,
            "last_name_accuracy": 0.11748139207402937,
            "last_name_precision": 1.6421232876712328,
            "weighted_score": 0.15145342989338162
        }
    }
}