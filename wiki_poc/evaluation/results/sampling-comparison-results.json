{
    "key": "sampling-comparison-results",
    "incite_instruct-3B--beam_search": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.2511578947368421,
            "precision": 0.6363421235674727,
            "last_name_accuracy": 0.1368421052631579,
            "last_name_precision": 1.0353846153846153,
            "weighted_score": 0.17685263157894737
        }
    },
    "bloomz-7B1--beam_search": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.3426315789473684,
            "precision": 0.4539519220798345,
            "last_name_accuracy": 0.2595789473684211,
            "last_name_precision": 1.0016220600162207,
            "weighted_score": 0.28864736842105265
        }
    },
    "flan_t5-11B--beam_search": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.3698947368421053,
            "precision": 0.4489478318499374,
            "last_name_accuracy": 0.26631578947368423,
            "last_name_precision": 1.0023715415019763,
            "weighted_score": 0.3025684210526316
        }
    },
    "incite_instruct-3B--greedy": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.22094736842105264,
            "precision": 0.5855391208808567,
            "last_name_accuracy": 0.1596842105263158,
            "last_name_precision": 1.022412656558998,
            "weighted_score": 0.1811263157894737
        }
    },
    "flan_t5-11B--greedy": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.25273684210526315,
            "precision": 0.500994963732606,
            "last_name_accuracy": 0.2054736842105263,
            "last_name_precision": 1.0030737704918034,
            "weighted_score": 0.2220157894736842
        }
    },
    "bloomz-7B1--greedy": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.24526315789473685,
            "precision": 0.4767273815924289,
            "last_name_accuracy": 0.19915789473684212,
            "last_name_precision": 1.0079281183932347,
            "weighted_score": 0.21529473684210526
        }
    },
    "incite_instruct-3B--nucleus_sampling": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.3162105263157895,
            "precision": 0.5689178986208955,
            "last_name_accuracy": 0.20989473684210527,
            "last_name_precision": 1.0215646940822467,
            "weighted_score": 0.24710526315789474
        }
    },
    "flan_t5-11B--nucleus_sampling": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.36926315789473685,
            "precision": 0.45018335977327467,
            "last_name_accuracy": 0.26589473684210524,
            "last_name_precision": 1.002375296912114,
            "weighted_score": 0.30207368421052627
        }
    },
    "bloomz-7B1--nucleus_sampling": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.3041052631578947,
            "precision": 0.4809227473780934,
            "last_name_accuracy": 0.2325263157894737,
            "last_name_precision": 1.006337709370756,
            "weighted_score": 0.2575789473684211
        }
    },
    "incite_instruct-3B--random_sampling": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.29189473684210526,
            "precision": 0.578701909834929,
            "last_name_accuracy": 0.19031578947368422,
            "last_name_precision": 1.0309734513274336,
            "weighted_score": 0.22586842105263158
        }
    },
    "flan_t5-11B--random_sampling": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.36905263157894735,
            "precision": 0.45072064283603924,
            "last_name_accuracy": 0.265578947368421,
            "last_name_precision": 1.0019817677368212,
            "weighted_score": 0.3017947368421052
        }
    },
    "bloomz-7B1--random_sampling": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.30336842105263156,
            "precision": 0.48138763953884206,
            "last_name_accuracy": 0.23010526315789473,
            "last_name_precision": 1.0077767612076853,
            "weighted_score": 0.2557473684210526
        }
    },
    "incite_instruct-3B--top_k_sampling": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.32,
            "precision": 0.572770951390411,
            "last_name_accuracy": 0.208,
            "last_name_precision": 1.0232793522267207,
            "weighted_score": 0.24719999999999998
        }
    },
    "flan_t5-11B--top_k_sampling": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.36926315789473685,
            "precision": 0.45018335977327467,
            "last_name_accuracy": 0.26589473684210524,
            "last_name_precision": 1.002375296912114,
            "weighted_score": 0.30207368421052627
        }
    },
    "bloomz-7B1--top_k_sampling": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.30747368421052634,
            "precision": 0.4857490005224411,
            "last_name_accuracy": 0.23210526315789473,
            "last_name_precision": 1.0068027210884354,
            "weighted_score": 0.25848421052631576
        }
    },
    "incite_instruct-3B--top_k_sampling_kruns": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.3263157894736842,
            "precision": 0.5668734433200342,
            "last_name_accuracy": 0.21810526315789475,
            "last_name_precision": 1.0173745173745175,
            "weighted_score": 0.2559789473684211
        }
    },
    "flan_t5-11B--top_k_sampling_kruns": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.36926315789473685,
            "precision": 0.45018335977327467,
            "last_name_accuracy": 0.26589473684210524,
            "last_name_precision": 1.002375296912114,
            "weighted_score": 0.30207368421052627
        }
    },
    "bloomz-7B1--top_k_sampling_kruns": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.3004210526315789,
            "precision": 0.4793499858789008,
            "last_name_accuracy": 0.23210526315789473,
            "last_name_precision": 1.0072562358276644,
            "weighted_score": 0.2560157894736842
        }
    },
    "incite_instruct-3B--top_p_sampling": {
        "size": 3.0,
        "paraphrased": {
            "accuracy": 0.30357894736842106,
            "precision": 0.5692164404079727,
            "last_name_accuracy": 0.1994736842105263,
            "last_name_precision": 1.0174142480211081,
            "weighted_score": 0.23591052631578946
        }
    },
    "flan_t5-11B--top_p_sampling": {
        "size": 11.0,
        "paraphrased": {
            "accuracy": 0.36926315789473685,
            "precision": 0.45018335977327467,
            "last_name_accuracy": 0.26589473684210524,
            "last_name_precision": 1.002375296912114,
            "weighted_score": 0.30207368421052627
        }
    },
    "bloomz-7B1--top_p_sampling": {
        "size": 7.1,
        "paraphrased": {
            "accuracy": 0.30136842105263156,
            "precision": 0.4807382222300977,
            "last_name_accuracy": 0.23336842105263159,
            "last_name_precision": 1.0076680198466397,
            "weighted_score": 0.2571684210526316
        }
    }
}