<!DOCTYPE html>
<html class="sl-theme-dark" id="base">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Thesis</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.0.0-beta.83/dist/themes/light.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.0.0-beta.83/dist/themes/dark.css" />

  <link type="text/css" rel="stylesheet" href="main.css" />
  <script type="module" src="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.0.0-beta.83/dist/shoelace.js"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;1,300;1,400&display=swap" rel="stylesheet">
<script type="text/javascript">
  if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
    document.getElementById("base").classList.add('sl-theme-dark');
  } else {
    document.getElementById("base").classList.remove('sl-theme-dark');
  }
</script>

</head>
<body>
  <sl-switch id="theme-toggle">Toggle Dark Mode</sl-switch>
  <script type="text/javascript">
    document.getElementById("theme-toggle").addEventListener("sl-change", function() {document.getElementById("base").classList.toggle("sl-theme-dark")});
  </script>
  <h1>Re-identification in court decisions</h1>

  <sl-tab-group placement="end" class="tabs">
    <sl-tab slot="nav" panel="log">Progress Log</sl-tab>
    <sl-tab slot="nav" panel="models">Models</sl-tab>

    <sl-tab-panel name="log">
      <h2 style="font-weight: 300">Progress Log</h2>
      <div class="log-section">

        <!-- log entry -->
        <div class="log-entry">
          <h3>Full Rebuild of Paraphrasing</h3>
          <div class="tags">
            <sl-badge variant="neutral">16.11.22</sl-badge>
            <sl-badge variant="primary">v1.3</sl-badge>
            <sl-badge variant="warning">REFACTORING</sl-badge>
          </div>

          <ul>
            <li>Out of of memory on gpu issue fixed by batching sentences independent of wiki pages.</li>
            <li>Rebuilt main loop of paraphrasing to efficiently use huggingface datasets caching.</li>
            <li>Usage of Ubelix array jobs to run jobs faster while using caching more easily.</li>
          </ul>
          <sl-details summary="Details">
          <h4>Memory Issues and sentence batching</h4>
          <p>In the first attempt pages were processed in batches and their sentences all joined to a long list to be processed by the model. This caused memory issues in some cases where by chance several larger pages were in the same batch. Instead of clipping sentences, the length of the input is now not decided by the number of pages in a batch, but the sentences are split to fit the approximate maximum input length for the model.</p>
          <p>Now pages are processed in batches, but for each badge of pages their sentences are concated to a large list, which is split up in parts which fit the size of the model, maximising the efficiency of the model, while still running stable. The overhead of splitting and rejoining text does not matter in comparison to the runtime of the paraphrasing itself.</p>
          <p>Running pages in batches also allows to cache the results easily with hugginface, as mapped functions on the dataset batches are cached by default. This allows to restart jobs if they failed at some point, without doing full recalcuations.</p>
          <h4>Ubelix array jobs</h4>
          <p>As the longest time possible to run on ubelix is 24h on the gpus required for paraphrasing, instead of creating a single 60h job, the dataset is now split into 7 parts, each containing around 10k pages. Each job then processes one such shard, splitting it again in 10 parts, resulting in a cache files for 7 jobs * 10 shards, which gives 70 savepoints during processing. Each holds around 1k wiki pages. After processing the datasets are concated back together for further processing.</p>

        </sl-details>
      </div>

        <!-- log entry -->
        <div class="log-entry">
          <h3>Paraphrasing Masks vs Normal Masks</h3>
          <div class="tags">
            <sl-badge variant="neutral">26.10.22</sl-badge>
            <sl-badge variant="primary">v1.3</sl-badge>
            <sl-badge variant="warning">REFACTORING</sl-badge>
          </div>

          <ul>
            <li>Switch processing to huggingface datasets, include caching.</li>
            <li>Fix memory issues for very long sentences, further improving paraphrasing performance.</li>
          </ul>
      </div>

        <!-- log entry -->
        <div class="log-entry">
          <h3>Paraphrasing Masks vs Normal Masks</h3>
          <div class="tags">
            <sl-badge variant="neutral">20.10.22</sl-badge>
            <sl-badge variant="primary">v1.2</sl-badge>
            <sl-badge variant="warning">ANALYSIS</sl-badge>
          </div>

          <ul>
            <li>Analyzed paraphrasing performance.</li>
            <li>Analysis of paraphrasing time.</li>
          </ul>

          <sl-details summary="Details">
          <h4>Paraphrasing time</h4>
          <p>With approximately 9 days running time for the first version, the time is now down to 9 hours.
          Increasing batch sizes, ditching sentences which are way too long and removing sections which cause the
          tokenizer to generate a lot of tokens for words it does know have in its default dictionary made the process
          much faster.</p>
          <h4>Results for Paraphrasing</h4>
          <p>Comparing the number of masks with the length of input texts,
          we find that paraphrased texts are on average one quarter shorter 
        than unparaphrased texts. The number of masks to text length is very similar between paraphrased and normal text (trendline). The average number of masks is about one quarter lower for paraphrased texts, which fits the shorter overall text length of paraphrased sentences. This is good news, it means paraphrasing does not lose any entities for reidentifaction.</p>
          <div class="img-container">
            <figure>
              <img src="images/masks_vs_text_length.png">
              <figcaption>Comparison of number of masks to length of text for normal and paraphrased text
              </figcaption>
            </figure>
          </div>
          <p>Comparing masks per sentence gives a better resolution on masks compared to their importance within sentences.</p>
          <div class="img-container">
            <figure>
              <img src="images/masks_vs_sentences_count.png">
              <figcaption>Comparison of number of masks per sentence for normal and paraphrased text in model</figcaption>
            </figure>
          </div>

        </sl-details>
      </div>

      <div class="log-entry">
        <h3>Fixing the Masking</h3>
        <div class="tags">
          <sl-badge variant="neutral">12.10.22</sl-badge>
          <sl-badge variant="primary">v1</sl-badge>
          <sl-badge variant="warning">REFACTORING</sl-badge>
        </div>

        <ul>
          <li>Switched from replacing entities in the text with regex to replacing them with the index given by NER.</li>
          <li>Added batching to NER so the tokenizer can tokenize the full input, allowing NER to detect all entities, not just within the first part of the text.</li>
        </ul>

        <sl-details summary="Details">
          <h4>Masking is now correct, we mask a word for every entity detected.</h4>
          <div class="img-compare">
            <figure>
            <img src="images/mask_vs_entities_v2.png">

            <img src="images/mask_vs_entities_v1.png">
            </figure>
          </div>
        </sl-details>
      </div>

      </div>
    </sl-tab-panel>

    <sl-tab-panel name="models">
      <sl-alert variant="warning" open>
        <sl-icon slot="icon" name="exclamation-triangle"></sl-icon>
        <strong>Oops!</strong><br />
        Nothing here yet.
      </sl-alert>
    </sl-tab-panel>
  </sl-tab-group>
</body>
</html>